{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10749</td>\n",
       "      <td>4</td>\n",
       "      <td>An imaginative comedy/thriller .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>5</td>\n",
       "      <td>( A ) rare , beautiful film .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10751</td>\n",
       "      <td>5</td>\n",
       "      <td>( An ) hilarious romantic comedy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10752</td>\n",
       "      <td>4</td>\n",
       "      <td>Never ( sinks ) into exploitation .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10753</td>\n",
       "      <td>1</td>\n",
       "      <td>( U ) nrelentingly stupid .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10754 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "0             4  The Rock is destined to be the 21st Century 's...\n",
       "1             5  The gorgeously elaborate continuation of `` Th...\n",
       "2             4  Singer/composer Bryan Adams contributes a slew...\n",
       "3             3  You 'd think by now America would have had eno...\n",
       "4             4               Yet the act is still charming here .\n",
       "...         ...                                                ...\n",
       "10749         4                   An imaginative comedy/thriller .\n",
       "10750         5                      ( A ) rare , beautiful film .\n",
       "10751         5                 ( An ) hilarious romantic comedy .\n",
       "10752         4                Never ( sinks ) into exploitation .\n",
       "10753         1                        ( U ) nrelentingly stupid .\n",
       "\n",
       "[10754 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_filename='dataset/sst_train.txt'\n",
    "test_filename='dataset/sst_test.txt'\n",
    "train_df = pd.read_csv(train_filename, sep='\\t', header=None, names=['sentiment', 'text'])\n",
    "test_df =pd.read_csv(test_filename, sep='\\t', header=None, names=['sentiment', 'text'])\n",
    "train_df['sentiment'] = train_df['sentiment'].str.replace('__label__', '')\n",
    "train_df['sentiment'] = train_df['sentiment'].astype(int).astype('category')\n",
    "test_df['sentiment'] = test_df['sentiment'].str.replace('__label__', '')\n",
    "test_df['sentiment'] = test_df['sentiment'].astype(int).astype('category')\n",
    "cols=train_df.columns\n",
    "data = pd.concat([train_df,test_df], ignore_index=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import Sequential\n",
    "\n",
    "def remove_punct(text): \n",
    "    # punctuation marks \n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  \n",
    "    for x in text.lower(): \n",
    "        if x in punctuations: \n",
    "            text = text.replace(x, \"\") \n",
    "  \n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    #Remove HyperText Links\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'^http?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'^ftp?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "# Clean Text\n",
    "data[\"text\"] = data.text.map(str) \\\n",
    "                            .map(lambda x: x.lower()) \\\n",
    "                            .map(lambda x: x.strip()) \\\n",
    "                            .map(lambda x: re.sub(r'\\d+', '', x)) \\\n",
    "                            .map(remove_punct) \\\n",
    "                            .map(remove_urls) \\\n",
    "                            .map(remove_html_tags)\n",
    "\n",
    "# Convert sentiment to int\n",
    "# sentiment_map = {\"1\"=\"positif\", \"2\"=\"negatif\"}\n",
    "# data[\"sentiment\"] = data.sentiment.map(lambda x: sentiment_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer=\"adam\", dropout=0.1, init='uniform', nbr_features=2500, dense_nparams=256):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_nparams, activation='relu', input_shape=(nbr_features,), kernel_initializer=init,)) \n",
    "    model.add(Dropout(dropout), )\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kears_estimator = KerasClassifier(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer =\"word\", \n",
    "                                                max_features=2500,)), \n",
    "                       ('ss', StandardScaler(with_mean=False,)), \n",
    "                       (\"kc\", kears_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (2,2), (1,3)],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'kc__epochs': [10, 100, ],\n",
    "    'kc__dense_nparams': [32, 256, 512],\n",
    "    'kc__init': [ 'uniform', 'zeros', 'normal', ], \n",
    "    'kc__batch_size':[2, 16, 32],\n",
    "    'kc__optimizer':['RMSprop', 'Adam', 'Adamax', 'sgd'],\n",
    "    'kc__dropout': [0.5, 0.4, 0.3, 0.2, 0.1, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.text\n",
    "y = data.sentiment\n",
    "kfold_splits = 5\n",
    "grid = GridSearchCV(estimator=estimator,  \n",
    "                    n_jobs=-1, \n",
    "                    verbose=1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,  #StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n",
    "                    param_grid=param_grid,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10368 candidates, totalling 51840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X, y, ) #callbacks=[tbCallBack]\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dense_layer_sizes, optimizer=\"adam\", dropout=0.1, init='uniform', nbr_features=2500, dense_nparams=256):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_nparams, activation='relu', input_shape=(nbr_features,), kernel_initializer=init,)) \n",
    "    model.add(Dropout(dropout), )\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(Dense(layer_size, activation='relu'))\n",
    "        model.add(Dropout(dropout), )\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
